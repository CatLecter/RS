services:
  movies_db:
    container_name: movies_db
    image: postgres:14.3-bullseye
    env_file:
      - ./movies_db/.env
    ports:
      - "5432:5432"
    volumes:
      - ./movies_db/volume:/var/lib/postgresql/data
      - ./movies_db/sql_scripts:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d movies"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  sqlite_to_postgres:
    container_name: sqlite_to_postgres
    build: ./sqlite_to_postgres/
    restart: on-failure
    env_file:
      - ./sqlite_to_postgres/.env
    volumes:
      - ./movies_sqlite/db.sqlite:/usr/src/sqlite_to_postgres/db.sqlite
    depends_on:
      movies_db:
        condition: service_healthy
    links:
      - movies_db

  movies_admin:
    build: ./movies_admin/
    container_name: admin_panel
    restart: always
    env_file:
      - ./movies_admin/.env
    expose:
      - 8000
    depends_on:
      movies_db:
        condition: service_healthy
    links:
      - movies_db

  elasticsearch:
    image: elasticsearch:7.17.3
    container_name: elasticsearch
    restart: always
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - es:/usr/share/elasticsearch/data
    expose:
      - 9200
    healthcheck:
      test: curl -u elastic:elastic -s -f elasticsearch:9200/_cat/health >/dev/null || exit 1
      interval: 30s
      timeout: 10s
      retries: 5

  etl:
    build: ./etl/
    container_name: etl
    restart: on-failure
    env_file:
      - ./etl/.env
    depends_on:
      elasticsearch:
        condition: service_healthy
      movies_db:
        condition: service_healthy

  search_cache:
    image: redis:7.0.0-bullseye
    expose:
      - 6379

  search_api:
    build: ./search_api/
    container_name: search_api
    restart: on-failure
    env_file:
      - ./search_api/.env
    expose:
      - 8000
    depends_on:
      elasticsearch:
        condition: service_healthy

  nginx:
    image: nginx:1.21.6
    container_name: nginx
    restart: on-failure
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/conf.d:/etc/nginx/conf.d
      - ./movies_admin/static/:/static
    ports:
      - "80:80"
    depends_on:
      - movies_admin
      - search_api

  zookeeper:
    image: zookeeper:3.8.0
    container_name: zookeeper
    hostname: zookeeper

  clickhouse-node1:
    image: clickhouse/clickhouse-server:22.3.6.5
    container_name: clickhouse-node1
    hostname: clickhouse-node1
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - ./ugc/data/node1:/etc/clickhouse-server
      - ./ugc/etl/clickhouse/config:/etc/clickhouse-server/config.d
      - ./ugc/CA.pem:/etc/CA.pem
    env_file:
      - ./ugc/.env
    depends_on:
      - zookeeper

  clickhouse-node2:
    image: clickhouse/clickhouse-server:22.3.6.5
    container_name: clickhouse-node2
    hostname: clickhouse-node2
    volumes:
      - ./ugc/data/node2:/etc/clickhouse-server
      - ./ugc/etl/clickhouse/config:/etc/clickhouse-server/config.d
      - ./ugc/CA.pem:/etc/CA.pem
    env_file:
      - ./ugc/.env
    depends_on:
      - zookeeper

  clickhouse-node3:
    image: clickhouse/clickhouse-server:22.3.6.5
    container_name: clickhouse-node3
    hostname: clickhouse-node3
    volumes:
      - ./ugc/data/node3:/etc/clickhouse-server
      - ./ugc/etl/clickhouse/config:/etc/clickhouse-server/config.d
      - ./ugc/CA.pem:/etc/CA.pem
    env_file:
      - ./ugc/.env
    depends_on:
      - zookeeper

  clickhouse-node4:
    image: clickhouse/clickhouse-server:22.3.6.5
    container_name: clickhouse-node4
    hostname: clickhouse-node4
    volumes:
      - ./ugc/data/node4:/etc/clickhouse-server
      - ./ugc/etl/clickhouse/config:/etc/clickhouse-server/config.d
      - ./ugc/CA.pem:/etc/CA.pem
    env_file:
      - ./ugc/.env
    depends_on:
      - zookeeper

  ugc_etl:
    build: ./ugc/etl
    container_name: ugc_etl
    env_file:
      - ./ugc/.env
    depends_on:
      - clickhouse-node1

  ugc:
    build: ./ugc/
    container_name: ugc
    restart: always
    env_file:
      - ./ugc/.env
    expose:
      - 8000
    volumes:
      - ./ugc/CA.pem:/etc/CA.pem
    logging:
      driver: gelf
      options:
        gelf-address: udp://127.0.0.1:5044
        tag: ugc

  auth_db:
    image: postgres:14.3-bullseye
    restart: always
    volumes:
      - auth_db:/var/lib/postgresql/data
    env_file:
      - ./auth/.env-db
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d movies"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  jaeger:
    image: jaegertracing/all-in-one:1.33.0
    ports:
      - "16686:16686"
      - "6831:6831"

  redis:
    image: redis:7.0.0-bullseye
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]

  auth:
    build: ./auth/
    env_file:
      - ./auth/.env-flask
    volumes:
      - ./auth/auth_api:/app/auth_api
      - ./auth/migrations:/app/migrations
    depends_on:
      movies_db:
        condition: service_healthy
      redis:
        condition: service_healthy
    expose:
      - 5000
    command: flask run -h 0.0.0.0

volumes:
  es:
  auth_db:
